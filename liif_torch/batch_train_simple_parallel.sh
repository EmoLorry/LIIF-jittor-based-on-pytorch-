#!/bin/bash
# åŒGPUå¹¶è¡Œè®­ç»ƒè„šæœ¬ - å……åˆ†åˆ©ç”¨GPU 0å’ŒGPU 1

set -e  # é‡åˆ°é”™è¯¯æ—¶åœæ­¢æ‰§è¡Œ

# é…ç½®å‚æ•°
MAX_PARALLEL_JOBS=2  # æœ€å¤šåŒæ—¶è¿è¡Œçš„ä»»åŠ¡æ•°ï¼ˆå¯¹åº”GPUæ•°é‡ï¼‰
GPUS=(0 1)           # å¯ç”¨çš„GPUè®¾å¤‡
LOG_DIR="./logs"     # æ—¥å¿—ç›®å½•

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p "${LOG_DIR}"

# ç®€å•çš„é…ç½®åˆ—è¡¨
configs=(
    "train-div2k/train_rdn-liif.yaml rdn_liif_v1"
    #"train-div2k/train_edsr-baseline-metasr.yaml edsr_metasr_v1"
    "train-div2k/ablation/train_edsr-baseline-liif-c.yaml edsr_liif_ablation_c"
    "train-div2k/ablation/train_edsr-baseline-liif-d.yaml edsr_liif_ablation_d"
    "train-div2k/ablation/train_edsr-baseline-liif-e.yaml edsr_liif_ablation_e"
    "train-div2k/ablation/train_edsr-baseline-liif-u.yaml edsr_liif_ablation_u"
    "train-div2k/ablation/train_edsr-baseline-liif-x2.yaml edsr_liif_ablation_x2"
    "train-div2k/ablation/train_edsr-baseline-liif-x3.yaml edsr_liif_ablation_x3"
    "train-div2k/ablation/train_edsr-baseline-liif-x4.yaml edsr_liif_ablation_x4"
)

# å‡½æ•°ï¼šè¿è¡Œå•ä¸ªè®­ç»ƒä»»åŠ¡
run_training() {
    local config_path=$1
    local exp_name=$2
    local gpu_id=$3
    
    echo "[$(date '+%H:%M:%S')] ğŸš€ å¼€å§‹è®­ç»ƒ: ${exp_name} (GPU ${gpu_id})"
    
    # é‡å®šå‘è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶
    python train.py --config ${config_path} --name ${exp_name} --gpu ${gpu_id} \
        > "${LOG_DIR}/${exp_name}_gpu${gpu_id}.log" 2>&1
    
    local exit_code=$?
    if [ $exit_code -eq 0 ]; then
        echo "[$(date '+%H:%M:%S')] âœ… å®Œæˆè®­ç»ƒ: ${exp_name} (GPU ${gpu_id})"
    else
        echo "[$(date '+%H:%M:%S')] âŒ è®­ç»ƒå¤±è´¥: ${exp_name} (GPU ${gpu_id}), é€€å‡ºä»£ç : ${exit_code}"
    fi
    
    return $exit_code
}

# ä¸»è®­ç»ƒå¾ªç¯
echo "ğŸ¯ å¼€å§‹æ‰¹é‡å¹¶è¡Œè®­ç»ƒ (æœ€å¤§å¹¶è¡Œæ•°: ${MAX_PARALLEL_JOBS})"
echo "ğŸ“ æ—¥å¿—ä¿å­˜è·¯å¾„: ${LOG_DIR}/"
echo "ğŸ–¥ï¸  å¯ç”¨GPU: ${GPUS[*]}"
echo "ğŸ“‹ æ€»ä»»åŠ¡æ•°: ${#configs[@]}"
echo "========================================"

running_jobs=0
gpu_index=0

for config_info in "${configs[@]}"; do
    read -r config_path exp_name <<< "${config_info}"
    
    # å¦‚æœè¾¾åˆ°æœ€å¤§å¹¶è¡Œæ•°ï¼Œç­‰å¾…ä¸€ä¸ªä»»åŠ¡å®Œæˆ
    if [ $running_jobs -ge $MAX_PARALLEL_JOBS ]; then
        wait -n  # ç­‰å¾…ä»»æ„ä¸€ä¸ªåå°ä»»åŠ¡å®Œæˆ
        running_jobs=$((running_jobs - 1))
    fi
    
    # åˆ†é…GPUï¼ˆè½®æµä½¿ç”¨ï¼‰
    gpu_id=${GPUS[$gpu_index]}
    gpu_index=$(( (gpu_index + 1) % ${#GPUS[@]} ))
    
    # åå°å¯åŠ¨è®­ç»ƒä»»åŠ¡
    run_training "$config_path" "$exp_name" "$gpu_id" &
    running_jobs=$((running_jobs + 1))
    
    echo "ğŸ“Š å½“å‰è¿è¡Œä»»åŠ¡æ•°: ${running_jobs}/${MAX_PARALLEL_JOBS}"
    echo "----------------------------------------"
    
    # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…åŒæ—¶å¯åŠ¨å¯¼è‡´èµ„æºå†²çª
    sleep 2
done

# ç­‰å¾…æ‰€æœ‰åå°ä»»åŠ¡å®Œæˆ
echo "â³ ç­‰å¾…æ‰€æœ‰è®­ç»ƒä»»åŠ¡å®Œæˆ..."
wait

echo ""
echo "ğŸ‰ æ‰€æœ‰è®­ç»ƒä»»åŠ¡å·²å®Œæˆï¼"
echo "ğŸ“ æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: ls ${LOG_DIR}/"
echo "ğŸ” æŸ¥çœ‹å…·ä½“æ—¥å¿—: tail -f ${LOG_DIR}/ä»»åŠ¡å_gpu*.log"